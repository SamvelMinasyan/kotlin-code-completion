{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fd525c",
   "metadata": {},
   "source": [
    "# Preparing Kotlin code completion dataset and finetuning the Phi 1.5 model using PEFT(Parameter-Efficient Fine-Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72ca2b",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from peft import PeftModel, LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e9e8a1",
   "metadata": {},
   "source": [
    "### Preparing Kotlin files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4075fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments_and_format_new_lines(source_code):\n",
    "    # Remove single line comments and the newline character immediately following it\n",
    "    source_code = re.sub(r'//.*?\\n', '\\n', source_code)\n",
    "    # Remove multi-line comments\n",
    "    source_code = re.sub(r'/\\*.*?\\*/', '', source_code, flags=re.DOTALL)\n",
    "    # Reduce three or more consecutive newlines to exactly two newlines\n",
    "    source_code = re.sub(r'\\n{3,}', '\\n\\n', source_code)\n",
    "    return source_code\n",
    "\n",
    "def load_and_clean_files(directory_path):\n",
    "    all_files = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.kt'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                cleaned_content = remove_comments_and_format_new_lines(content)\n",
    "                all_files.append(cleaned_content)\n",
    "    return all_files\n",
    "\n",
    "def split_dataset(data, train_ratio=0.6, val_ratio=0.2):\n",
    "    random.shuffle(data)\n",
    "    total = len(data)\n",
    "    train_end = int(total * train_ratio)\n",
    "    val_end = int(total * (train_ratio + val_ratio))\n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Load and clean the data\n",
    "directory_path = 'kotlin_files'\n",
    "data = load_and_clean_files(directory_path)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, val_data, test_data = split_dataset(data)\n",
    "\n",
    "with open('train_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for item in train_data:\n",
    "        f.write(f\"{item}\\n\\n\")\n",
    "\n",
    "with open('val_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for item in val_data:\n",
    "        f.write(f\"{item}\\n\\n\")\n",
    "\n",
    "with open('test_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for item in test_data:\n",
    "        f.write(f\"{item}\\n\\n\")\n",
    "\n",
    "print(\"Data preparation complete. Data split into training, validation, and test sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bbc04",
   "metadata": {},
   "source": [
    "### Load a pretrained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5868a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca20bee",
   "metadata": {},
   "source": [
    "### Configure model quantization and Parameter Efficient Fine-Tuning (PEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/phi-1_5\",\n",
    "    device_map={\"\":0},\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97364e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f98ae",
   "metadata": {},
   "source": [
    "### Apply PEFT to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7523604",
   "metadata": {},
   "source": [
    "### Load the dataset and prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = \"\"\n",
    "with open(\"val_data.txt\", \"r\") as f:\n",
    "    val_data = f.read()\n",
    "    \n",
    "chunk_size = 2000\n",
    "text_chunks = [val_data[i:i + chunk_size] for i in range(0, len(val_data), chunk_size)]\n",
    "\n",
    "val_df = pd.DataFrame(text_chunks, columns=['text'])\n",
    "val_df['Prompt'] = val_df['text'].str[:1000]\n",
    "val_df['Completion'] = val_df['text'].str[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb9d33",
   "metadata": {},
   "source": [
    "### Create a combined text field for tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"text\"] = val_df[[\"Prompt\", \"Completion\"]].apply(lambda x: \"Prompt: \" + x[\"Prompt\"] + \" Completion: \" + x[\"Completion\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ab859",
   "metadata": {},
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    tokenized_text =  tokenizer(sample[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e377ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(val_df)\n",
    "\n",
    "tokenized_data = data.map(tokenize, batched=True, desc=\"Tokenizing data\", remove_columns=data.column_names)\n",
    "\n",
    "# Split the tokenized data into training and test sets\n",
    "dataset = tokenized_data.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a8630",
   "metadata": {},
   "source": [
    "### Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "        output_dir=\"phi-1_5-finetuned-med-text\",\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=2e-4,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=100,\n",
    "        max_steps=1000,\n",
    "        num_train_epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171500e",
   "metadata": {},
   "source": [
    "### Function to compute metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ea7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    # Logic is missing because when I tried to run the evaluation with compute_metrics I was running into \"OutOfMemoryError: CUDA out of memory\" error\n",
    "    \n",
    "    return {\n",
    "        \"BLEU\": sentence_bleu,\n",
    "        \"ROUGE-L\": Rouge().get_scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c67233",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82703a80",
   "metadata": {},
   "source": [
    "### Initialize and run the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074cdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=training_arguments,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "#     compute_metrics=compute_metrics\n",
    ")\n",
    "a = trainer.evaluate(eval_dataset)\n",
    "print(a)\n",
    "trainer.train()\n",
    "b = trainer.evaluate(eval_dataset)\n",
    "print(b)\n",
    "\n",
    "# Training loss is decreasing but I was not able to compute all metrics because of \"OutOfMemoryError: CUDA out of memory\" issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bc8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c8cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
